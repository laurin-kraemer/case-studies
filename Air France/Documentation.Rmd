---
title: "Workbook"
output:
  pdf_document: default
  html_document: default
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part 1: Motivation

### Problem Statement
- High Costs per click with SEM (Search Engine Marketing)
- Airline industry a Competitive market with Low margins

### State the Questions
- Where do we allocate our marketing budget most efficiently?
- How can we reduce Cost/Click, increase revenue and optimize performance? 
- Which search engine delivers the most ROI? (Manuel)
- what are the customer segments / search engine
  --> Specific pattern in buying behavior?

### Main Objectives
- Find out profitability of campaigns / search engines / keywords
- Compare different bid strategies
- Which platform offers the most visibility?
- Find out single-click conversion rate of branded / unbranded keywords?

## What could be a positive outcome?
- Minimize Cost/Click
- Maximize ROA
- Maximize Single-click conversion

# Part 2: Method

## What key resources do we acquire?

- Description Data:

Useful variables in the dataset (Type: xls)

- $impressions

Features of interest
- costs per publisher
- $Cost / Click
- cost / $campaigns
- costs / $bidstrategy


2. R Libraries

```{r message=FALSE, warning=FALSE}
# Import Libraries
library(readxl)
library(tidyr)
library(plotly)
library(dplyr)
```


## What is our approach to solve the problem?

High level process of steps 

# Part 3: Mechanics

### Inspect & Import data
R tries to import the first sheet of the excel file which resolves in an error. This is why the argument read_excel function has to be used to specify the column.

```{r message=FALSE, warning=FALSE}

# Inspect sheets of excel-file
excel_sheets('Spreadsheet_Data.xls')
```

```{r message=FALSE}
# Import data
kayak <- read_excel("Spreadsheet_Data.xls", 
                                                     sheet = "Kayak")

doubleclick <- read_excel("Spreadsheet_Data.xls", 
                         sheet = "DoubleClick")

```

### Massaging


```{r}
#Convert to dataframe
doubleclick_clean <- as.data.frame(doubleclick)

#Look for weird stuff
colSums(is.na(doubleclick_clean))
table(doubleclick_clean$`Bid Strategy`)

# Replace NA entries  in bid strategy with Unassigned
doubleclick_clean$`Bid Strategy`[is.na(doubleclick_clean$`Bid Strategy`)] = "Unassigned"

# Notice how the number of rows gets reduced 
print(nrow(doubleclick_clean))

# Look for Spelling mistakes
unique(doubleclick_clean $`Bid Strategy`)

# Replace Typos
doubleclick_clean$`Bid Strategy` <- gsub("Postiion 1-4 Bid Strategy","Position 1-4 Bid Strategy",doubleclick_clean$`Bid Strategy`)

doubleclick_clean$`Bid Strategy` <- gsub("Position 1 -2 Target","Position 1-2 Target",doubleclick_clean$`Bid Strategy`)

```

## Descriptive

```{r}

# Count of observations

# Create data set for analysis
sem <- doubleclick_clean[,c('Campaign','Keyword','Keyword Group','Publisher Name', 'Bid Strategy','Engine Click Thru %','Match Type','Trans. Conv. %','Total Cost/ Trans.','Impressions','Total Volume of Bookings')]

# Get a big picture understanding of the data
summary(sem)
str(sem)

# Find out most frequently used bid strategy
table(sem$`Bid Strategy`)

# Find out unique publishers
unique(sem$`Publisher Name`)

# Average out the clickthroughs per publisher
clickthrough_publisher <- aggregate(sem$`Engine Click Thru %`, by=list(sem$`Publisher Name`), FUN=mean) 

# Visualize average clickthroughs per publisher
plot_ly(clickthrough_publisher, x = clickthrough_publisher$`Group.1`, y=~`x`,title = 'Average Clickthrough rate of different publisher')%>%
        layout(title = 'Clickthrough per Publisher', plot_bgcolor = "#e5ecf6",xaxis = list(title = 'Publisher'),yaxis = list(title = 'Clickthrough Rate in %'))

# Sum up Transactions per publisher
transactions_publisher <- aggregate(sem$`Total Volume of Bookings`, by=list(sem$`Publisher Name`), FUN=sum) 

# Visualize transactions per publisher
plot_ly(transactions_publisher, x = transactions_publisher$`Group.1`, y=~`x`,title = 'Bookings per publisher')%>%
        layout(title = 'Bookings per publisher', plot_bgcolor = "#e5ecf6",xaxis = list(title = 'Publisher'),yaxis = list(title = 'Transactions'))


# What are the overall average costs / transaction
avg_costs_transaction <- print(mean(sem$`Total Cost/ Trans.`))

# Average out the costs per transaction per publisher
costs_publisher <- aggregate(sem$`Total Cost/ Trans.`, by=list(sem$`Publisher Name`), FUN=mean) 

# Visualize average costs per transaction per engine
plot_ly(costs_publisher, x = costs_publisher$`Group.1`, y=~`x`)%>%
        layout(title = 'Average Costs per Publisher', plot_bgcolor = "#e5ecf6",xaxis = list(title = 'Publisher'),yaxis = list(title = 'Costs / Transaction'))

```
It seems like Google-US has the highest clickthrough rate and the costs / click are unusually high for Yahoo - US. One reason could be the advanced Match Type that gets Air France uses on that engine.

Yahoo-US has the highest percentage of click through rate with and impressive ~16%. What makes this output so impressive is that Yahoo-US has the second lowest  cost per campaign with an average of $7.95, and Yahoo-US is still able to concure the top three Transactions per publishes with a total of 662.


```{r}

# Total Cost per Transaction - Distribution per Publisher
plot_ly(sem,y = ~`Total Cost/ Trans.`, color = ~`Publisher Name`, type = "box")

# Visualize distribution of Bid Strategies for single Publishers
plot_ly(sem[which(sem$`Publisher Name`=='Google - US'),], x = ~`Publisher Name`, y = ~`Total Cost/ Trans.`, color = ~`Bid Strategy`, type = "box")

# Visualize impressions per campaign
plot_ly(doubleclick_clean, x = doubleclick_clean$`Campaign`, y=~Impressions, type='bar')

```
```{r variable_distribution}

library('GGally')

# Select all the numerical variables
logic <- sapply(sem, is.numeric)
numerical_var <- sem[,logic]

# Select all the numerical variables
#logic <- sapply(doubleclick_clean, is.numeric)
#numerical_var <- doubleclick_clean[,logic]

numerical_var_standardized <- as.data.frame(scale(numerical_var))

p <- ggpairs(numerical_var_standardized, title="correlogram with ggpairs()") 
ggplotly(p)

```


Most impressions come from unassigned keywords. 

```{r}

# Select observations with the highest total cost per transaction
sem_sub <- subset(sem,subset = `Total Cost/ Trans.` > 0)

# Visualize the costs per transactions for different Publisher
p <- plot_ly(sem_sub, y = ~`Total Cost/ Trans.`, color = I("black"), 
             alpha = 0.2, boxpoints = "suspectedoutliers")
p1 <- p %>% add_boxplot(x = ~`Publisher Name`)
p1

# Visualize the converted transactions for different bid strategies
convert_bid <- plot_ly(sem_sub, y = ~`Trans. Conv. %`, color = I("black"), 
             alpha = 0.2, boxpoints = "suspectedoutliers")
p2 <- p %>% add_boxplot(x = ~`Bid Strategy`)
p2

# Visualize the numerical variables in 3D-Space
plot_ly(sem, x = ~`Engine Click Thru %`, y = ~`Trans. Conv. %`, z =~`Total Cost/ Trans.`) %>%
  add_markers(color = ~`Trans. Conv. %`)

```

### Keywords

```{r}
ggplot(data=doubleclick_clean, aes(x=sem$`Trans. Conv.`, y=sem$`Total Cost/ Trans.`, color=sem$`Publisher Name`)) + geom_point() + scale_y_continuous(trans='log10') + scale_x_continuous(trans='log10')

```

## Predictive

Feature Selection
Model




# Message

Key Findings

The C-suite of ___ face the following (problem/challenge), which is best solved with _ (solution) having an impact and/or making profits via ___ . The unique advantages/differentiators of the MVP are ____ , when comparing with the following key competitors / alternatives: ___

Next steps(What needs to be done!)

- Do branded keywords bring in more revenue?
- Are broad or focused keywords more profitable?
- Can assist keywords help increase conversion rate?

